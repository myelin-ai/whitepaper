Second generation neural networks achieve impressive results
on all tasks that can collectively be identified as data classification.
As of the time of writing, second generation convolutional networks
continue dominating every ImageNet classification challenge of the last
years~\cite{ILSVRC15}.

There are still types of tasks however that no deep learning topology or 
technique has been able to tackle so far. Adversarial evaluations of reading comprehension
systems indicate that neural networks that excell at evaluating carefully
prepared data prove to be extremely fragile when encountering organic ``noise''
information~\cite{DBLP:journals/corr/JiaL17}.
The practice of splitting learning into separate training and application steps
means that a traditional neural network is unable to continuously learn while working.
This way, new information cannot be aquired dynamically as it has to be spoon-fed in the
form of carefully prepared test data.
Further limitations of current deep learning strategies have been compiled by 
Gary Marcus~\cite{DBLP:journals/corr/abs-1801-00631}.

One way to interpret these limitations is as an expression of the growing discrepancy between
biological neural networks and the mentioned systems~\cite{Paugam-Moisy2012}.

\subsubsection{General Intelligence in nature}
In light of these dissatisfactions with the current state of AI, we take a deliberate step back 
from current research and ask ourselves what the goal of artificial intelligence research should actually be.
In our opinion, AI is not about the automation of simple tasks or the labeling of pictures. 
Artificial Intelligence should be about intelligence. And the only form of intelligence that can truly
stimulate and satisfy the human being is one, that is similar to its own inner workings: A general intelligence,
flexible enough to adapt to an everchanging environment, enduring enough to continuously learn and change its approach.
So far, the only general intelligence that we know of resides within our own heads. It is therefore tempting to
build an Artificial General Intelligence by simply replicating the human brain in an artificial setting. In practice
however, this approach proves to be only advantageous when studying in situ micromodels and 
their effects in isolation~\cite{Dudai2014}. We interpret this effect as a concequence of the wrong level of abstraction.
